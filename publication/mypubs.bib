@inproceedings{Williams2018,
  title = "Recognizing Emotions in Video Using Multimodal {DNN} Feature Fusion",
  author = "Williams, Jennifer  and
    Kleinegesse, Steven  and
    Comanescu, Ramona  and
    Radu, Oana",
  booktitle = "Proceedings of Grand Challenge and Workshop on Human Multimodal Language (Challenge-{HML})",
  month = jul,
  year = "2018",
  address = "Melbourne, Australia",
  publisher = "Association for Computational Linguistics",
  url = "https://www.aclweb.org/anthology/W18-3302",
  pages = "11--19",
  abstract = "We present our system description of input-level multimodal fusion of audio, video, and text for recognition of emotions and their intensities for the 2018 First Grand Challenge on Computational Modeling of Human Multimodal Language. Our proposed approach is based on input-level feature fusion with sequence learning from Bidirectional Long-Short Term Memory (BLSTM) deep neural networks (DNNs). We show that our fusion approach outperforms unimodal predictors. Our system performs 6-way simultaneous classification and regression, allowing for overlapping emotion labels in a video segment. This leads to an overall binary accuracy of 90{\%}, overall 4-class accuracy of 89.2{\%} and an overall mean-absolute-error (MAE) of 0.12. Our work shows that an early fusion technique can effectively predict the presence of multi-label emotions as well as their coarse-grained intensities. The presented multimodal approach creates a simple and robust baseline on this new Grand Challenge dataset. Furthermore, we provide a detailed analysis of emotion intensity distributions as output from our DNN, as well as a related discussion concerning the inherent difficulty of this task.",
}

@InProceedings{Kleinegesse2018,
  title =    {Efficient Bayesian Experimental Design for Implicit Models},
  author =   {Kleinegesse, Steven and Gutmann, Michael U.},
  booktitle =    {Proceedings of Machine Learning Research},
  pages =    {476--485},
  year =   {2019},
  editor =   {Chaudhuri, Kamalika and Sugiyama, Masashi},
  volume =   {89},
  series =   {Proceedings of Machine Learning Research},
  address =    {},
  month =    {Apr},
  publisher =    {PMLR},
  pdf =    {http://proceedings.mlr.press/v89/kleinegesse19a/kleinegesse19a.pdf},
  url =    {http://proceedings.mlr.press/v89/kleinegesse19a.html},
  abstract =   {Bayesian experimental design involves the optimal allocation of resources in an experiment, with the aim of optimising cost and performance. For implicit models, where the likelihood is intractable but sampling from the model is possible, this task is particularly difficult and therefore largely unexplored. This is mainly due to technical difficulties associated with approximating posterior distributions and utility functions. We devise a novel experimental design framework for implicit models that improves upon previous work in two ways. First, we use the mutual information between parameters and data as the utility function, which has previously not been feasible. We achieve this by utilising Likelihood-Free Inference by Ratio Estimation (LFIRE) to approximate posterior distributions, instead of the traditional approximate Bayesian computation or synthetic likelihood methods. Secondly, we use Bayesian optimisation in order to solve the optimal design problem, as opposed to the typically used grid search or sampling-based methods. We find that this increases efficiency and allows us to consider higher design dimensions.}
}
