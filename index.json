[{"authors":["admin"],"categories":null,"content":"I am a PhD student at the Centre of Doctoral Training (CDT) in Data Science at the University of Edinburgh. My research interests include Bayesian experimental design, likelihood-free inference and Bayesian optimisation. Prior to being a PhD student, I graduated with a Master of Science in Physics from Imperial College London, where I specialised in Astrophysics and Particle Physics.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://stevenkleinegesse.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"I am a PhD student at the Centre of Doctoral Training (CDT) in Data Science at the University of Edinburgh. My research interests include Bayesian experimental design, likelihood-free inference and Bayesian optimisation. Prior to being a PhD student, I graduated with a Master of Science in Physics from Imperial College London, where I specialised in Astrophysics and Particle Physics.","tags":null,"title":"Steven Kleinegesse","type":"author"},{"authors":["Steven Kleinegesse","Michael U. Gutmann"],"categories":null,"content":"","date":1582070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582070400,"objectID":"5c713ff9f328f8932460c1620eba2bb7","permalink":"https://stevenkleinegesse.github.io/publication/bayesian-experimental-design-for-implicit-models-by-mutual-information/","publishdate":"2020-02-19T00:00:00Z","relpermalink":"/publication/bayesian-experimental-design-for-implicit-models-by-mutual-information/","section":"publication","summary":"Implicit stochastic models, where the data-generation distribution is intractable but sampling is possible, are ubiquitous in the natural sciences. The models typically have free parameters that need to be inferred from data collected in scientific experiments. A fundamental question is how to design the experiments so that the collected data are most useful. The field of Bayesian experimental design advocates that, ideally, we should choose designs that maximise the mutual information (MI) between the data and the parameters. For implicit models, however, this approach is severely hampered by the high computational cost of computing posteriors and maximising MI, in particular when we have more than a handful of design variables to optimise. In this paper, we propose a new approach to Bayesian experimental design for implicit models that leverages recent advances in neural MI estimation to deal with these issues. We show that training a neural network to maximise a lower bound on MI allows us to jointly determine the optimal design and the posterior. Simulation studies illustrate that this gracefully extends Bayesian experimental design for implicit models to higher design dimensions.","tags":[],"title":"Bayesian Experimental Design for Implicit Models by Mutual Information","type":"publication"},{"authors":["Steven Kleinegesse","Michael U. Gutmann"],"categories":null,"content":"","date":1554073200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554073200,"objectID":"d9267b741d7c3cd22298eef2818d67a0","permalink":"https://stevenkleinegesse.github.io/publication/efficient-bayesian-experimental-design-for-implicit-models/","publishdate":"2019-04-01T00:00:00+01:00","relpermalink":"/publication/efficient-bayesian-experimental-design-for-implicit-models/","section":"publication","summary":"Bayesian experimental design involves the optimal allocation of resources in an experiment, with the aim of optimising cost and performance. For implicit models, where the likelihood is intractable but sampling from the model is possible, this task is particularly difficult and therefore largely unexplored. This is mainly due to technical difficulties associated with approximating posterior distributions and utility functions. We devise a novel experimental design framework for implicit models that improves upon previous work in two ways. First, we use the mutual information between parameters and data as the utility function, which has previously not been feasible. We achieve this by utilising Likelihood-Free Inference by Ratio Estimation (LFIRE) to approximate posterior distributions, instead of the traditional approximate Bayesian computation or synthetic likelihood methods. Secondly, we use Bayesian optimisation in order to solve the optimal design problem, as opposed to the typically used grid search or sampling-based methods. We find that this increases efficiency and allows us to consider higher design dimensions.","tags":[],"title":"Efficient Bayesian Experimental Design for Implicit Models","type":"publication"},{"authors":["J. Griffiths","S. Kleinegesse","D. Saunders","R. Taylor","A. Vacheret"],"categories":null,"content":"","date":1531868400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531868400,"objectID":"dc3a6043cd1956cb1d78b5cfeff97a4d","permalink":"https://stevenkleinegesse.github.io/publication/pulse-shape-discrimination-and-exploration-of-scintillation-signals-using-convolutional-neural-networks/","publishdate":"2018-07-18T00:00:00+01:00","relpermalink":"/publication/pulse-shape-discrimination-and-exploration-of-scintillation-signals-using-convolutional-neural-networks/","section":"publication","summary":"We demonstrate the use of a convolutional neural network to perform neutron-gamma pulse shape discrimination, where the only inputs to the network are the raw digitised SiPM signals from a dual scintillator detector element made of 6LiF:ZnS(Ag) scintillator and PVT plastic. A realistic labelled dataset was created to train the network by exposing the detector to an AmBe source, and a data-driven method utilsing a separate PMT was used to assign labels to the recorded signals. This approach is compared to the charge integration and continuous wavelet transform methods and is found to provide superior levels of discrimination, achieving an AUC of 0.995 +/- 0.003. We find that the neural network is capable of extracting interpretable features directly from the raw data. In addition, by visualising the high-dimensional representations of the network with the t-SNE algorithm, we discover that not only is this method robust to minor mislabeling of the training dataset but that it is possible to identify an underlying substructure within the signals that goes beyond the original labelling. This technique could be utilised to explore and cluster complex, raw detector data in a novel way that may reveal more insights than standard analysis methods.","tags":[],"title":"Pulse Shape Discrimination and Exploration of Scintillation Signals Using Convolutional Neural Networks","type":"publication"},{"authors":["Jennifer Williams","Steven Kleinegesse","Ramona Comanescu","Oana Radu"],"categories":null,"content":"","date":1530399600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530399600,"objectID":"d147cd00e2662e3cd92967cbeb954e05","permalink":"https://stevenkleinegesse.github.io/publication/recognizing-emotions-in-video-using-multimodal-dnn-feature-fusion/","publishdate":"2018-07-01T00:00:00+01:00","relpermalink":"/publication/recognizing-emotions-in-video-using-multimodal-dnn-feature-fusion/","section":"publication","summary":"We present our system description of input-level multimodal fusion of audio, video, and text for recognition of emotions and their intensities for the 2018 First Grand Challenge on Computational Modeling of Human Multimodal Language. Our proposed approach is based on input-level feature fusion with sequence learning from Bidirectional Long-Short Term Memory (BLSTM) deep neural networks (DNNs). We show that our fusion approach outperforms unimodal predictors. Our system performs 6-way simultaneous classification and regression, allowing for overlapping emotion labels in a video segment. This leads to an overall binary accuracy of 90%, overall 4-class accuracy of 89.2% and an overall mean-absolute-error (MAE) of 0.12. Our work shows that an early fusion technique can effectively predict the presence of multi-label emotions as well as their coarse-grained intensities. The presented multimodal approach creates a simple and robust baseline on this new Grand Challenge dataset. Furthermore, we provide a detailed analysis of emotion intensity distributions as output from our DNN, as well as a related discussion concerning the inherent difficulty of this task.","tags":[],"title":"Recognizing Emotions in Video Using Multimodal DNN Feature Fusion","type":"publication"}]